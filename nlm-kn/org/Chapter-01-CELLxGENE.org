* Chapter 01: Use of CELLxGENE

Ray LeClair <2024-10-23 Wed>

** Objectives

Since CELLxGENE serves as an initiating data source for the NLM
Knowledge Network pilot, the objectives of this document include
demonstration of:

- Identification of CELLxGENE datasets for specified organisms, and
  tissues

- Identification of publications corresponding to CELLxGENE datasets

- Determination of the dataset filename and dataset file download

*** Background

All single-cell RNA data from Chan Zuckerberg (CZ) CELLxGENE Discover
is accessed, queried, and analyzed using the CELLxGENE Discover
Census. Using cell-based slicing and querying one can:

- Interact with the data through TileDB-SOMA

- Get slices in AnnData, Seurat, or SingleCellExperiment objects

See: [[https://chanzuckerberg.github.io/cellxgene-census/][CELLxGENE Discover Census]]

The following sections draw from CZ CELLxGENE tutorials, or a Chan
Zuckerberg Initiative (CZI) repository, which demonstrate how to:

- [[https://chanzuckerberg.github.io/cellxgene-census/notebooks/analysis_demo/comp_bio_explore_and_load_lung_data.html][Explore and query the Census in the context of a single tissue, lung]]

- [[https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_query_extract.html][Query the expression data and cell/gene metadata from the Census, and load them into common in-memory Python objects]]

- [[https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_citation_generation.html][Generate a citation string for all datasets contained in a Census slice]]

- [[https://github.com/chanzuckerberg/single-cell-curation/blob/0c77179d2e794846861f8109c037b723507959cb/notebooks/curation_api/python_raw/get_dataset.ipynb][Fetch full metadata for a Dataset]]

The following sections describe various development environments

See: [[https://github.com/ralatsdc/springbok-nlm-kn/blob/main/README.md][springbok-nlm-kn/README.md]]

*** Jupyter Notebook development environment

Launch Jupyter Notebook from a terminal in which ~.zshenv~ has been
sourced, and the virtual environment has been activated.

*** Emacs Org Mode development environment

Launch Emacs from a terminal in which ~.zshenv~ has been sourced, then
evaluate this code block to activate the virtual environment:

#+begin_src emacs-lisp :session shared :results silent
  (pyvenv-activate "../../.venv")
#+end_src

** Identification of CELLxGENE datasets for specified organisms, and tissues

Mostly following the first tutorial, we write a function that obtains
all datasets, summary cell counts, gene metadata, and, by default,
human and mouse lung, eye, and brain cell metadata from the CZ
CELLxGENE Census as Pandas DataFrames. Anticipating a time consuming
process, the first call of the function writes the DataFrames to
~.parquet~ files, then, on subsequent calls, it reads the ~.parquet~
files. In both cases, the resulting DataFrames are returned.

To begin, we import modules, and assign module scope variables:

#+begin_src python :results silent :session shared :tangle ../py/CELLxGENE.py
  import logging
  import os
  import re
  import subprocess
  from time import sleep
  from traceback import print_exception

  import cellxgene_census

  from bs4 import BeautifulSoup
  import pandas as pd
  import requests

  DATA_DIR = "../data"

  CELLXGENE_DOMAIN_NAME = "cellxgene.cziscience.com"
  CELLXGENE_API_URL_BASE = f"https://api.{CELLXGENE_DOMAIN_NAME}"
  CELLXGENE_DIR = f"{DATA_DIR}/cellxgene"

  NLM_KN_DIR = f"{DATA_DIR}/nlm-kn"

  HTTPS_SLEEP = 1
#+end_src

Next we write the function:

#+begin_src python :results silent :session shared :tangle ../py/CELLxGENE.py
  def get_metadata_and_datasets(
      organisms=["homo_sapiens", "mus_musculus"], tissues=["lung", "eye", "brain"]
  ):
      """Use the CZ CELLxGENE Census to obtain all datasets, summary
      cell counts, gene metadata, and, by default, human and mouse
      lung, eye, and brain cell metadata, then write the resulting
      Pandas DataFrames to parquet files, or, if the files exist, read
      them.

      Parameters
      ----------
      organisms : list(str)
          List of organisms, default is ["homo_sapiens", "mus_musculus"]
      tissues : list(str)
          List of tissues, default is ["lung", "eye", "brain"]

      Returns
      -------
      datasets : pd.DataFrame
          DataFrame containing dataset descriptions
      counts : pd.DataFrame
          DataFrame containing summary cell counts
      var : pd.DataFrame
          DataFrame containing gene metadata
      obs : pd.DataFrame
          DataFrame containing cell metadata
      """
      # Create and write, or read DataFrames
      datasets_parquet = f"{NLM_KN_DIR}/datasets.parquet"
      counts_parquet = f"{NLM_KN_DIR}/counts.parquet"
      var_parquet = f"{NLM_KN_DIR}/var.parquet"
      obs_parquet = f"{NLM_KN_DIR}/obs.parquet"
      if (
          not os.path.exists(datasets_parquet)
          or not os.path.exists(counts_parquet)
          or not os.path.exists(var_parquet)
          or not os.path.exists(obs_parquet)
      ):
          print("Opening soma")
          census = cellxgene_census.open_soma(census_version="latest")

          print("Collecting all datasets")
          datasets = census["census_info"]["datasets"].read().concat().to_pandas()

          print("Collecting summary cell counts")
          counts = (
              census["census_info"]["summary_cell_counts"].read().concat().to_pandas()
          )

          var = pd.DataFrame()
          for organism in organisms:
              print(f"Collecting gene metadata for {organism}")
              var = pd.concat(
                  [
                      var,
                      cellxgene_census.get_var(
                          census,
                          organism,
                      ),
                  ]
              )

          obs = pd.DataFrame()
          for organism in organisms:
              print(f"Collecting cell metadata for {organism}: {tissues} tissue")
              obs_for_org = cellxgene_census.get_obs(
                  census,
                  organism,
                  value_filter=f"tissue_general in {tissues} and is_primary_data == True",
              )
              obs_for_org["organism"] = organism
              obs = pd.concat(
                  [
                      obs,
                      obs_for_org,
                  ]
              )

          print("Closing soma")
          census.close()

          print("Writing datasets parquet")
          datasets.to_parquet(datasets_parquet)

          print("Writing summary cell counts parquet")
          counts.to_parquet(counts_parquet)

          print("Writing gene metadata parquet")
          var.to_parquet(var_parquet)

          print("Writing cell metadata parquet")
          obs.to_parquet(obs_parquet)

      else:

          print("Reading datasets parquet")
          datasets = pd.read_parquet(datasets_parquet)

          print("Reading summary cell counts parquet")
          counts = pd.read_parquet(counts_parquet)

          print("Reading gene metadata parquet")
          var = pd.read_parquet(var_parquet)

          print("Reading cell metadata parquet")
          obs = pd.read_parquet(obs_parquet)

      return datasets, counts, var, obs
#+end_src

Then call it to obtain the human and mouse lung, eye, and brain cell
metadata and datasets (using exception handling since accessing an
external resource), and print the result:

#+begin_src python :results output :session shared
  try:
      datasets, counts, var, obs = get_metadata_and_datasets()
  except Exception as exc:
      print_exception(exc)
  print(f"datasets:\n\ncolumns: {datasets.columns}\n\n{datasets}")
  print()
  print(f"counts:\n\ncolumns: {counts.columns}\n\n{counts}")
  print()
  print(f"var:\n\ncolumns: {var.columns}\n\n{var}")
  print()
  print(f"obs:\n\ncolumns: {obs.columns}\n\n{obs}")
#+end_src

#+RESULTS:
#+begin_example
Reading datasets parquet
Reading summary cell counts parquet
Reading gene metadata parquet
Reading cell metadata parquet
datasets:

columns: Index(['soma_joinid', 'citation', 'collection_id', 'collection_name',
       'collection_doi', 'collection_doi_label', 'dataset_id',
       'dataset_version_id', 'dataset_title', 'dataset_h5ad_path',
       'dataset_total_cell_count'],
      dtype='object')

     soma_joinid  ... dataset_total_cell_count
0              0  ...                      565
1              1  ...                      146
2              2  ...                      363
3              3  ...                     3799
4              4  ...                     1324
..           ...  ...                      ...
951          951  ...                  3177310
952          952  ...                  3267338
953          953  ...                 11441407
954          954  ...                  1226855
955          955  ...                  1309414

[956 rows x 11 columns]

counts:

columns: Index(['soma_joinid', 'organism', 'category', 'label', 'ontology_term_id',
       'total_cell_count', 'unique_cell_count'],
      dtype='object')

      soma_joinid      organism        category            label ontology_term_id  total_cell_count  unique_cell_count
0               0  Homo sapiens             all               na               na          86410648           51835017
1               1  Homo sapiens           assay         Drop-seq      EFO:0008722            338069             292631
2               2  Homo sapiens           assay           inDrop      EFO:0008780             51304              25652
3               3  Homo sapiens           assay         MARS-seq      EFO:0008796             70146              70146
4               4  Homo sapiens           assay         Seq-Well      EFO:0008919            255232             137955
...           ...           ...             ...              ...              ...               ...                ...
1896         1896  Mus musculus  tissue_general   exocrine gland   UBERON:0002365             46731              15577
1897         1897  Mus musculus  tissue_general   prostate gland   UBERON:0002367            130135              37715
1898         1898  Mus musculus  tissue_general  endocrine gland   UBERON:0002368             39966              13322
1899         1899  Mus musculus  tissue_general      bone marrow   UBERON:0002371            199699              90225
1900         1900  Mus musculus  tissue_general        optic cup   UBERON:0003072               146                146

[1901 rows x 7 columns]

var:

columns: Index(['soma_joinid', 'feature_id', 'feature_name', 'feature_length', 'nnz',
       'n_measured_obs'],
      dtype='object')

       soma_joinid          feature_id       feature_name  feature_length       nnz  n_measured_obs
0                0     ENSG00000237491          LINC01409            1059   7266057        75339772
1                1     ENSG00000188976              NOC2L            1244  15080647        86077006
2                2     ENSG00000187642              PERM1            2765    537346        75481456
3                3     ENSG00000272512  ENSG00000272512.1            2086    805209        76397515
4                4     ENSG00000188290               HES4             961  15402916        85816634
...            ...                 ...                ...             ...       ...             ...
52432        52432  ENSMUSG00002076766            Snord33              84       612           73347
52433        52433  ENSMUSG00000118601            Gm53042             814        10          301796
52434        52434  ENSMUSG00000118631            Gm53019            1593         5          301796
52435        52435  ENSMUSG00000118645            Gm55062             480         0               0
52436        52436  ENSMUSG00000118652            Gm54771             358         1          301796

[113875 rows x 6 columns]

obs:

columns: Index(['soma_joinid', 'dataset_id', 'assay', 'assay_ontology_term_id',
       'cell_type', 'cell_type_ontology_term_id', 'development_stage',
       'development_stage_ontology_term_id', 'disease',
       'disease_ontology_term_id', 'donor_id', 'is_primary_data',
       'observation_joinid', 'self_reported_ethnicity',
       'self_reported_ethnicity_ontology_term_id', 'sex',
       'sex_ontology_term_id', 'suspension_type', 'tissue',
       'tissue_ontology_term_id', 'tissue_type', 'tissue_general',
       'tissue_general_ontology_term_id', 'raw_sum', 'nnz', 'raw_mean_nnz',
       'raw_variance_nnz', 'n_measured_vars', 'organism'],
      dtype='object')

         soma_joinid                            dataset_id      assay  ... raw_variance_nnz n_measured_vars      organism
0              69389  2f6a20f1-173d-4b8d-860b-c47ffea120fa  10x 3' v2  ...       122.226277           19884  homo_sapiens
1              69390  2f6a20f1-173d-4b8d-860b-c47ffea120fa  10x 3' v2  ...        76.797450           19884  homo_sapiens
2              69391  2f6a20f1-173d-4b8d-860b-c47ffea120fa  10x 3' v2  ...        73.692622           19884  homo_sapiens
3              69392  2f6a20f1-173d-4b8d-860b-c47ffea120fa  10x 3' v2  ...        72.729032           19884  homo_sapiens
4              69393  2f6a20f1-173d-4b8d-860b-c47ffea120fa  10x 3' v2  ...       127.932705           19884  homo_sapiens
...              ...                                   ...        ...  ...              ...             ...           ...
3859649     12264935  d7291f04-fbbb-4d65-990a-f01fa44e915b  10x 3' v2  ...        40.448180           28102  mus_musculus
3859650     12264936  d7291f04-fbbb-4d65-990a-f01fa44e915b  10x 3' v2  ...        78.175412           28102  mus_musculus
3859651     12264937  d7291f04-fbbb-4d65-990a-f01fa44e915b  10x 3' v2  ...         8.890497           28102  mus_musculus
3859652     12264938  d7291f04-fbbb-4d65-990a-f01fa44e915b  10x 3' v2  ...        28.916028           28102  mus_musculus
3859653     12264939  d7291f04-fbbb-4d65-990a-f01fa44e915b  10x 3' v2  ...        88.272342           28102  mus_musculus

[28721975 rows x 29 columns]
#+end_example

We can merge some of the resulting DataFrames to create a summary
DataFrame for export.  As before, we will write the summary DataFrame
to a ~.parquet~ file, so that later we can simply read the ~.parquet~
file.

#+begin_src python :results output :session shared
  summary_parquet = f"{NLM_KN_DIR}/summary.parquet"
  if not os.path.exists(summary_parquet):
      # Define columns needed from obs
      obs_columns = [
          "organism",
          "tissue_general",
          "tissue_general_ontology_term_id",
          "assay",
          "assay_ontology_term_id",
          "dataset_id",
      ]

      # Define columns required for summary
      sum_columns = [
          "organism",
          "tissue_general",
          "tissue_general_ontology_term_id",
          "collection_id",
          "collection_name",
          "collection_doi",
          "assay",
          "assay_ontology_term_id",
          "dataset_id",
          "dataset_title",
          "dataset_h5ad_path",
      ]

      print("Merging datasets and obs DataFrames")
      try:
          summary = pd.merge(
              datasets, obs[obs_columns].drop_duplicates(), on="dataset_id"
          )[sum_columns].drop_duplicates()
      except Exception as exc:
          print_exception(exc)

      print("Writing summary parquet")
      summary.to_parquet(summary_parquet)

      print("Writing summary CSV")
      summary_csv = f"{NLM_KN_DIR}/summary.csv"
      summary.to_csv(summary_csv)

  else:
      print("Reading summary parquet")
      summary = pd.read_parquet(summary_parquet)
#+end_src

#+RESULTS:
: Merging datasets and obs DataFrames
: Writing summary parquet
: Writing summary CSV

** Identification of publications corresponding to CELLxGENE datasets

We notice that the datasets DataFrame contains a ~citation~ column,
for example:

#+begin_src python :results output :session shared
  print(datasets["citation"].iloc[4])
#+end_src

#+RESULTS:
: Publication: https://doi.org/10.1038/s41586-019-0903-2 Dataset Version: https://datasets.cellxgene.cziscience.com/701a5b3f-d30f-49d9-97ce-c89523875b81.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/16c1e722-96ae-4bf6-b408-cd7f8918484f

The ~citation~ provides the DOI, but not the title of the
publication. Note that we will need the title later in Chapter 02:
E-Utilities. So, we examine the ~collection_name~ and ~dataset_title~
columns:

See: [[file:Chapter-02-E-Utilities.ipynb][Chapter-02-E-Utilities.ipynb]]

#+begin_src python :results output :session shared
  print(datasets[["collection_name", "dataset_title"]].iloc[4, :])
#+end_src

#+RESULTS:
: collection_name    Single nuclei RNA- sequencing from the white m...
: dataset_title                                 Oligodendrocytes in MS
: Name: 88, dtype: object

But it appears we still need to find the title by some method. So, we
write a function that requests the DOI, then parses the resulting
page, most likely from the publisher, to find the title.

#+begin_src python :results silent :session shared :tangle ../py/CELLxGENE.py
  def get_title(citation):
      """Get the title given a dataset citation. Note that only wget
      succeeded for Cell Press journals, and neither requests nor wget
      succeeded for The EMBO Journal and Science.

      Parameters
      ----------
      citation : str
          Dataset citation

      Returns
      -------
      title : str
          Title of publication associated with the dataset
      """
      # Need a default return value
      title = None

      # Compile patterns for finding the publication URL and article
      # title
      p1 = re.compile("Publication: (.*) Dataset Version:")
      p2 = re.compile("articleName : '(.*)',")

      # Assign CSS selectors for selecting article title elements
      selectors = [
          "h1.c-article-title",
          "h1.article-header__title.smaller",
          "div.core-container h1",
          "h1.content-header__title.content-header__title--xx-long",
          "h1#page-title.highwire-cite-title",
      ]

      # Find the publication URL
      m1 = p1.search(citation)
      if not m1:
          logging.warning(f"Could not find citation URL for {citation}")
          return title
      citation_url = m1.group(1)
      print(f"Getting title for citation URL: {citation_url}")

      # Attempt to get the publication page using requests
      print(f"Trying requests")
      sleep(HTTPS_SLEEP)
      response = requests.get(citation_url)
      try_wget = True
      if response.status_code == 200:
          html_data = response.text

          # Got the page, so parse it, and try each selector
          fullsoup = BeautifulSoup(html_data, features="lxml")
          for selector in selectors:
              selected = fullsoup.select(selector)
              if selected:

                  # Selected the article title, so assign it
                  if len(selected) > 1:
                      logging.warning(
                          f"Selected more than one element using {selector} on soup from {citation_url}"
                      )
                  title = selected[0].text
                  try_wget = False
                  break

      if try_wget:

          # Attempt to get the publication page using wget
          print(f"Trying wget")
          sleep(HTTPS_SLEEP)
          completed_process = subprocess.run(
              ["curl", "-L", citation_url], capture_output=True
          )
          html_data = completed_process.stdout

          # Got the page, so parse it, and search for the title
          fullsoup = BeautifulSoup(html_data, features="lxml")
          found = fullsoup.find_all("script")
          if found and len(found) > 4:
              m2 = p2.search(found[4].text)
              if m2:
                  title = m2.group(1)

      print(f"Found title: '{title}' for citation URL: {citation_url}")

      return title
#+end_src

Next we call the function for an example citation (again using
exception handling since accessing an external resource):

#+begin_src python :results output :session shared
  try:
      citation = datasets["citation"].iloc[4]
      title = get_title(citation)
  except Exception as exc:
      print_exception(exc)
#+end_src

#+RESULTS:
: Getting title for citation URL: https://doi.org/10.1038/s41586-019-0903-2
: Trying requests
: Found title: 'Altered human oligodendrocyte heterogeneity in multiple sclerosis' for citation URL: https://doi.org/10.1038/s41586-019-0903-2

Note that the function attempts to use ~requests~, and if it fails,
~wget~, since some publishers respond to one, but not the other. The
selectors were discovered by manually inspecting the pages returned
for the human lung cell datasets using Google Chrome Developer Tools.

** Determine the dataset filename and download the dataset file.

Following a notebook found in a CZI repository, we write a function to
find the dataset filename, and to download the dataset file, given a
row of the datasets DataFrame obtained above:

#+begin_src python :results silent :session shared :tangle ../py/CELLxGENE.py
  def get_and_download_dataset_h5ad_file(dataset_series):
      """Get the dataset filename and download the dataset file.

      Parameters
      ----------
      dataset_series : pd.Series
          A row from the dataset DataFrame

      Returns
      -------
      dataset : str
         The dataset filename
      """
      # Need a default return value
      dataset_filename = None

      # Get the dataset object
      collection_id = dataset_series.collection_id
      dataset_id = dataset_series.dataset_id
      dataset_url = f"{CELLXGENE_API_URL_BASE}/curation/v1/collections/{collection_id}/datasets/{dataset_id}"
      sleep(HTTPS_SLEEP)
      response = requests.get(dataset_url)
      response.raise_for_status()
      if response.status_code != 200:
          logging.error(f"Could not get dataset for id {dataset_id}")
          return

      data = response.json()
      if dataset_id != data["dataset_id"]:
          logging.error(
              f"Response dataset id: {data['dataset_id']} does not equal specified dataset id: {dataset_id}"
          )
          return

      # Find H5AD files, if possible
      assets = data["assets"]
      for asset in assets:
          if asset["filetype"] != "H5AD":
              continue

          # Found an H5AD file, so download it, if needed
          dataset_filename = f"{dataset_id}.{asset['filetype']}"
          dataset_filepath = f"{CELLXGENE_DIR}/{dataset_filename}"
          if not os.path.exists(dataset_filepath):
              print(f"Downloading dataset file: {dataset_filepath}")
              with requests.get(asset["url"], stream=True) as response:
                  response.raise_for_status()
                  with open(dataset_filepath, "wb") as df:
                      for chunk in response.iter_content(chunk_size=1024 * 1024):
                          df.write(chunk)
              print(f"Dataset file: {dataset_filepath} downloaded")

          else:
              print(f"Dataset file: {dataset_filepath} exists")

      return dataset_filename
#+end_src

Then call it using the first row of the datasets DataFrame obtained
above, and print the result (we'll use exception handling when
accessing an external resource from now on):

#+begin_src python :results output :session shared
  try:
      dataset_series = datasets.iloc[4]
      get_and_download_dataset_h5ad_file(dataset_series)
  except Exception as exc:
      print_exception(exc)
#+end_src

#+RESULTS:
: Downloading dataset file: ../data/cellxgene/dc30c3ec-46d6-4cd8-8ec1-b544a3d0f503.H5AD
: Dataset file: ../data/cellxgene/dc30c3ec-46d6-4cd8-8ec1-b544a3d0f503.H5AD downloaded

Next, in Chapter 02 we write functions to search PubMed for the title
and identifiers.

See: [[file:Chapter-02-E-Utilities.ipynb][Chapter-02-E-Utilities.ipynb]]
